{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag-of-words using gensim.\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import pickle\n",
    "\n",
    "path = '/Users/nemo/hku/mfin7036/nlp-ferrari'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor i in range(0,len(text_list)):\\n    print (text_list[i])\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#f = open(\"C:/Users/34433/Desktop/MFFT/Courses/MFIN7036 NLP/pure_articles/AAPL/2011-01-18T23_05_21-05_00_Apple Management Discusses Q1 2011 Results - Earnings Call Transcript.html\",'r',encoding='utf-8')\n",
    "def parse_html(file_path):\n",
    "    f = open(file_path,'r',encoding='utf-8')\n",
    "    htmlhandle=f.read()\n",
    "    s= BeautifulSoup(htmlhandle,'lxml')\n",
    "    text_list = [text for text in s.stripped_strings]\n",
    "    return text_list\n",
    "'''\n",
    "for i in range(0,len(text_list)):\n",
    "    print (text_list[i])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    if \\'Executives\\' in raw:\\n        if \"Analysts\" in raw:\\n            mgmt_names = [name.split(\\' - \\')[0].split(\\' – \\')[0] for name in raw[6:raw.index(\\'Analysts\\')]]\\n            analyst_names = [name.split(\\' - \\')[0].split(\\' – \\')[0] for name in raw[raw.index(\\'Analysts\\')+1:raw.index(\\'Operator\\')]]\\n        elif \\'Conference Call Participants\\' in raw:\\n            mgmt_names = [name.split(\\' - \\')[0].split(\\' – \\')[0] for name in raw[6:raw.index(\\'Conference Call Participants\\')]]\\n            analyst_names = [name.split(\\' - \\')[0].split(\\' – \\')[0] for name in raw[raw.index(\\'Conference Call Participants\\')+1:raw.index(\\'Operator\\')]]\\n    elif \\'Company Participants\\' in raw:\\n    elif \\'Unverified Participant\\' in raw:\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_mgmt_names(raw):\n",
    "    hint_mgmt = ['Executives','Company Participants','Unverified Participant','Company Representatives','Corporate Participants']\n",
    "    hint_analyst = ['Analysts','Conference Call Participants']\n",
    "    hint_operator = ['Unidentified Company Representative','Operator']\n",
    "    mgmt_index_flag = raw.index([x for x in hint_mgmt if x in raw ][0])\n",
    "    # Some earnings call are without analysts\n",
    "    try:\n",
    "        analyst_index_flag = raw.index([x for x in hint_analyst if x in raw ][0])\n",
    "    except:\n",
    "        try: # Some transcripts may not have Analysts\n",
    "            analyst_index_flag = raw.index(\"Operator\")\n",
    "        except: # Some transcripts may even not have Operator\n",
    "            for t in raw:\n",
    "                if len(t.split(\" \"))>35:\n",
    "                    analyst_index_flag = raw.index(t)-1 # \"-1\"To make follwing analyst names blank\n",
    "                    break\n",
    "    # Deal with transcripts that do not start from Operator\n",
    "    try:\n",
    "        operator_index_flag = raw.index([x for x in hint_operator if x in raw ][0])\n",
    "    except:\n",
    "        for t in raw:\n",
    "            if len(t.split(\" \"))>35:\n",
    "                operator_index_flag = raw.index(t)\n",
    "                break\n",
    "    if operator_index_flag >25:\n",
    "        for t in raw:\n",
    "            if len(t.split(\" \"))>35:\n",
    "                operator_index_flag = raw.index(t)\n",
    "                break\n",
    "    #print (\"THE OPERATOR FLAG: \",operator_index_flag )\n",
    "    if set(raw[mgmt_index_flag+1:analyst_index_flag]) & set (raw[operator_index_flag:]) == set():\n",
    "        mgmt_names = [name.split(' - ')[0].split(' – ')[0] for name in raw[mgmt_index_flag+1:analyst_index_flag]]\n",
    "        try:\n",
    "            if analyst_index_flag != raw.index(\"Operator\"): \n",
    "                # Set this condition to make sure analyst exist\n",
    "                analyst_names = [name.split(' - ')[0].split(' – ')[0] for name in raw[analyst_index_flag+1:operator_index_flag]]                \n",
    "            else:\n",
    "                analyst_names = []\n",
    "        except:\n",
    "            analyst_names = []\n",
    "    else:\n",
    "        #print (\"??????? THE SET IS ????\", set(raw[mgmt_index_flag+1:analyst_index_flag]) & set (raw[operator_index_flag:]))\n",
    "        mgmt_names = raw[mgmt_index_flag+1:analyst_index_flag]\n",
    "        analyst_names = raw[analyst_index_flag+1:operator_index_flag]\n",
    "    return mgmt_names, analyst_names\n",
    "'''\n",
    "    if 'Executives' in raw:\n",
    "        if \"Analysts\" in raw:\n",
    "            mgmt_names = [name.split(' - ')[0].split(' – ')[0] for name in raw[6:raw.index('Analysts')]]\n",
    "            analyst_names = [name.split(' - ')[0].split(' – ')[0] for name in raw[raw.index('Analysts')+1:raw.index('Operator')]]\n",
    "        elif 'Conference Call Participants' in raw:\n",
    "            mgmt_names = [name.split(' - ')[0].split(' – ')[0] for name in raw[6:raw.index('Conference Call Participants')]]\n",
    "            analyst_names = [name.split(' - ')[0].split(' – ')[0] for name in raw[raw.index('Conference Call Participants')+1:raw.index('Operator')]]\n",
    "    elif 'Company Participants' in raw:\n",
    "    elif 'Unverified Participant' in raw:\n",
    "'''\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mgmt_discussion(text_list, mgmt_names,analyst_names):\n",
    "    hints = mgmt_names+analyst_names+['Operator','Unidentified Company Representative']\n",
    "    #print(hints)\n",
    "    combined_strs = []\n",
    "    for i in range(0,len(mgmt_names)):\n",
    "        disc = []\n",
    "        flag = -1\n",
    "        for text in text_list:\n",
    "            if text ==mgmt_names[i]  and flag == -1:\n",
    "                flag=flag * -1\n",
    "                #print ('Find the name')\n",
    "            elif text not in hints and flag ==1:\n",
    "                disc.append(text)\n",
    "                #print(\"$$$$$$$$Append {}'s text\".format(mgmt_names[i]))\n",
    "            elif text in hints and flag ==1:\n",
    "                flag=flag*-1\n",
    "                #print ('End this paragraph')\n",
    "            elif text not in hints and flag== -1:\n",
    "                continue\n",
    "        combined_str = (\"\\n\\n\".join(disc))\n",
    "        #print (combined_str)\n",
    "        #print (\"------------------------------------------\")\n",
    "        combined_strs.append(combined_str)       \n",
    "    #print (\"********The length of STR list is {} ***********\".format(len(combined_strs)))\n",
    "    return (\"\\n\\n\").join(combined_strs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = pd.read_csv(path + '/data/locations.csv')\n",
    "articles = articles[articles['Children'] == False]\n",
    "articles = articles[articles['Company'] != 'WMT']\n",
    "articles = articles[articles['Company'] != 'GOOGL']\n",
    "articles.dropna(inplace=True)\n",
    "\n",
    "articles.sort_values(by=['Company', 'Date'], inplace=True)\n",
    "articles.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(row):\n",
    "    file_path = path + '/data' + row['Path']\n",
    "    text_list=parse_html(file_path)\n",
    "    # print (\"###TEXT GET###\")\n",
    "    mgmt_names, analyst_names = get_mgmt_names(text_list)\n",
    "    #print (\"*** MGMT ***\",mgmt_names , analyst_names)\n",
    "    combined_strs = get_mgmt_discussion(text_list, mgmt_names,analyst_names)\n",
    "    return combined_strs\n",
    "\n",
    "#str_arr = articles.head(2).apply(get_text, axis=1)\n",
    "str_arr = articles.apply(get_text, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(str_arr.to_list(), open('./data/articles_arr.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [word_tokenize(s.lower()) for s in str_arr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_stops = [[t for t in token if t not in stopwords.words('english') and t.isalnum() and len(t) > 1] for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(no_stops, open(path + '/data/no_stops_words.p', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "46871df94ef8bf4d6d09bb814809c54070b9d3b7beb6b0833b6d009c707a5610"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
